{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdae595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, uniform\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.misc import derivative\n",
    "from scipy.integrate import quad\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import norm, uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe835898",
   "metadata": {},
   "source": [
    "### In this case we'll explore the case for multiple data set. We consider that the total distance is given by \n",
    "$$\n",
    "\n",
    "d_{\\rm tot} = \\sum_{i} \\omega_i d_{i} \\left(X_{\\rm obs,i}, X_{\\rm sim,i} \\right)\n",
    "$$\n",
    "### where $i$ runs over the number of multiple data set. \n",
    "### In this example we'll use SN Ia and BAO data to constrain CPL model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59657fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_distance(sn_obs, sn_err, sn_sim,\n",
    "                     bao_obs, bao_err, bao_sim,\n",
    "                     weights=None):\n",
    "    if weights is None:\n",
    "        weights = {'hubble': 1.0, 'sn': 1.0, 'bao': 1.0}\n",
    "\n",
    "    d_sn = sn_distance(sn_obs, sn_err, sn_sim)\n",
    "    d_bao = bao_distance(bao_obs, bao_err, bao_sim)\n",
    "    \n",
    "    # Weighted combination\n",
    "    total_distance = (weights['sn'] * d_sn +\n",
    "                     weights['bao'] * d_bao)\n",
    "    \n",
    "    return total_distance\n",
    "\n",
    "\n",
    "def sn_distance(observed, errors, simulated):\n",
    "    \"\"\"Distance metric for Supernovae data (distance modulus)\"\"\"\n",
    "    residuals = (observed - simulated) / errors\n",
    "    return np.sum(residuals**2)\n",
    "\n",
    "def bao_distance(observed, errors, simulated):\n",
    "    \"\"\"Distance metric for BAO data (distance ratios)\"\"\"\n",
    "    residuals = (observed - simulated) / errors\n",
    "    return np.sum(residuals**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ddafb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Omega_m0 = 0.3\n",
    "Omega_L0 = 0.7\n",
    "h = 0.71\n",
    "H0 = h *100\n",
    "zvals = np.linspace(0,3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "769a61b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosmological distances \n",
    "\n",
    "def hubble_normalized_cpl(z, w0, wa):\n",
    "    \n",
    "    matter_term = Omega_m0 * (1 + z)**3\n",
    "    \n",
    "    de_term = Omega_L0 * (1+z)**(3*(1+w0+wa)) * np.exp(-3*wa*z/(1+z))\n",
    "    return  H0 * np.sqrt(matter_term + de_term)\n",
    "\n",
    "def H():\n",
    "       return 100*h\n",
    "\n",
    "def HUBz(z,w0,wa):\n",
    "    return H()*hubble_normalized_cpl(z,w0,wa)\n",
    "\n",
    "def inverse_hubble_normalized_cpl(z,w0,wa):\n",
    "\n",
    "    return 1./hubble_normalized_cpl(z,w0,wa)\n",
    "\n",
    "def hubble_normalized_a(a,w0,wa):\n",
    "    return hubble_normalized_cpl(1./a-1,w0,wa)\n",
    "\n",
    "def hubble_prime_normalized_a(a,w0,wa):\n",
    "    return derivative(hubble_normalized_a(a,w0,wa), a, dx=1e-6)\n",
    "\n",
    "def D_H():\n",
    "    \"\"\"\n",
    "    Hubble distance in units of MPc (David Hogg arxiv: astro-ph/9905116v4)\n",
    "    \"\"\"\n",
    "    return 2997.98/h\n",
    "\n",
    "def comoving_distance_cpl(z,w0,wa):\n",
    "    return D_H() *quad(inverse_hubble_normalized_cpl(z,w0,wa),0, z,epsabs=1e-6, epsrel=1e-6, limit=200)[0]\n",
    "\n",
    "# angular diameter distance in units of MPc\n",
    "def angular_diameter_distance_cpl(z,w0,wa):\n",
    "    \"\"\"\n",
    "    Angular diameter distance as function of redshift z\n",
    "    in units of MPc\n",
    "    \"\"\"\n",
    "    d_c = comoving_distance_cpl(z,w0,wa)/(1.+z)\n",
    "    return d_c\n",
    "\n",
    "# luminosity distance in units of MPc\n",
    "def luminosity_distance_cpl(z,w0,wa):\n",
    "    d_c = comoving_distance_cpl(z,w0,wa)\n",
    "    return (1 + z) * d_c\n",
    "\n",
    "def build_luminosity_distance_interpolator(w0,wa,zmax=1.5,npoints=150):\n",
    "    zgrid = np.linspace(1e-4, zmax, npoints)\n",
    "    dLgrid = np.array([luminosity_distance_cpl(z,w0,wa) for z in zgrid])\n",
    "    _dL_interp = interp1d(zgrid, dLgrid, kind='cubic', bounds_error=False, fill_value='extrapolate')\n",
    "    _zmax_interp = zmax\n",
    "\n",
    "def luminosity_distance_fast(z):\n",
    "    if hasattr('_dL_interp') and z <= _zmax_interp:\n",
    "        return _dL_interp(z)\n",
    "    else:\n",
    "        return luminosity_distance_cpl(z,w0,wa)\n",
    "\n",
    "def distance_modulus(z,w0,wa):\n",
    "    try:\n",
    "        dL = luminosity_distance_fast(z,w0,wa)\n",
    "        return 5 * np.log10(dL) + 25\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] distance_modulus failed at z = {z}: {e}\")\n",
    "        return 1e6  # Return large chi2 penalty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2353fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA: \n",
    "data = pd.read_csv('/Users/alfonsozapata/Documents/SimpleMC/simplemc/data/binned_pantheon.txt', sep=r'\\s+')\n",
    "zcmb = data['zcmb']\n",
    "\n",
    "\n",
    "arr_hub = np.loadtxt('/Users/alfonsozapata/Documents/SimpleMC/simplemc/data/Hz_all.dat')\n",
    "z_obs= arr_hub[:,0]\n",
    "hub_obs = arr_hub[:,1]\n",
    "error_obs = arr_hub[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84cc06c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mu_sim(w0,wa): \n",
    "    mod = np.array([distance_modulus(z,w0,wa) for z in zcmb])\n",
    "    return mod\n",
    "\n",
    "def Hubble_sim(w0, wa):\n",
    "    try:\n",
    "        Hz_sim = np.array([hubble_normalized_cpl(z, w0, wa) for z in z_obs])\n",
    "        # Check for   # for NaN entries \n",
    "        if np.any(~np.isfinite(Hz_sim)) or np.any(Hz_sim <= 0):\n",
    "            return None\n",
    "        return Hz_sim\n",
    "  \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88049308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation of the data\n",
    "#mu_sim = mu_sim(w0,wa)\n",
    "#Hz_sim = Hubble_sim(w0,wa)\n",
    "def dist1_sn(mu_obs,mu_sim,cov_filename):\n",
    "    filename = cov_filename\n",
    "        \n",
    "    print(\"Loading covariance from {}\".format(filename))\n",
    "    f = open(filename)\n",
    "    line = f.readline()\n",
    "    n = int(len(self.zcmb))\n",
    "    C = np.zeros((n,n))\n",
    "    ii = -1\n",
    "    jj = -1\n",
    "    mine = 999\n",
    "    maxe = -999\n",
    "    for i in range(self.origlen):\n",
    "        jj = -1\n",
    "        if self.ww[i]:\n",
    "            ii += 1\n",
    "        for j in range(self.origlen):\n",
    "            if self.ww[j]:\n",
    "                jj += 1\n",
    "            val = float(f.readline())\n",
    "            if self.ww[i]:\n",
    "                if self.ww[j]:\n",
    "                    C[ii,jj] = val\n",
    "    f.close()\n",
    "    print('Done')\n",
    "    self.cov = C\n",
    "    self.xdiag = 1/self.cov.diagonal()\n",
    "\n",
    "\n",
    "\n",
    "    data = pd.read_csv(values_filename, delim_whitespace=True)\n",
    "    origlen = len(data)\n",
    "    tvec = mu_obs - mu_sim\n",
    "    tvec -= (tvec * xdiag).sum() / (xdiag.sum())\n",
    "   '''\n",
    "   The intrinsic supernova absolute magnitude M \n",
    "   is marginalized out by subtracting a weighted mean:\n",
    "   '''\n",
    "    \n",
    "    return abs(np.mean(mu_obs) - np.mean(mu_sim))\n",
    "\n",
    "\n",
    "\n",
    "def dist2_hub(observed, errors, simulated):\n",
    "    if simulated is None:\n",
    "        return np.inf\n",
    "    \n",
    "    return np.sum((observed - simulated)**2 / errors**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24465996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "061e50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need define our priors for the parameters w0 and wa \n",
    "def prior_w0():\n",
    "    return uniform.rvs(loc=-2.0, scale=1.0)\n",
    "def prior_wa():\n",
    "    return uniform.rvs(loc=-1.0, scale=2.0)\n",
    "prior_samples_0 = [prior_w0() for _ in range(10)]\n",
    "prior_samples_a = [prior_wa() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9f5ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_sim_cpl(prior_w0, prior_wa, zcmb, z_obs, observed_data_mu, observed_data_h, errors_mu, errors_h,\n",
    "                     epsilon, n_accepted, n_sims_before_update=100000, max_simulations=10**7, verbose=True):\n",
    "    \"\"\"\n",
    "    ABC rejection sampling for CPL dark energy parameters using both distance modulus and Hubble data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    prior_w0, prior_wa: functions that sample from priors for w0 and wa\n",
    "    zcmb: array of CMB redshifts for distance modulus calculation using compressed data in this case\n",
    "    z_obs: array of redshifts for Hubble parameter calculation  \n",
    "    observed_data_mu: observed distance modulus data\n",
    "    observed_data_h: observed Hubble parameter data\n",
    "    errors_mu: errors for distance modulus data\n",
    "    errors_h: errors for Hubble parameter data\n",
    "    epsilon: tolerance threshold for acceptance\n",
    "    n_accepted: target number of accepted samples\n",
    "    n_sims_before_update: frequency of progress updates\n",
    "    max_simulations: maximum number of simulations before stopping\n",
    "    verbose: whether to print progress information\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the simulation functions\n",
    "    def mu_sim(w0, wa): \n",
    "        \"\"\"Simulate distance modulus for given w0, wa parameters\"\"\"\n",
    "        mod = np.array([distance_modulus(z, w0, wa) for z in zcmb])\n",
    "        return mod\n",
    "\n",
    "    def Hubble_sim(w0, wa):\n",
    "        \"\"\"Simulate Hubble parameter for given w0, wa parameters\"\"\"\n",
    "        try:\n",
    "            Hz_sim = np.array([hubble_normalized_cpl(z, w0, wa) for z in z_obs])\n",
    "            # Check for invalid values\n",
    "            if np.any(~np.isfinite(Hz_sim)) or np.any(Hz_sim <= 0):\n",
    "                return None\n",
    "            return Hz_sim\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def combined_distance(observed_data_mu, errors_mu, observed_data_h, errors_h, simulated_data_mu, simulated_data_h):\n",
    "        \"\"\"\n",
    "        Combined distance metric using both distance modulus and Hubble data\n",
    "        Uses chi-squared like distance metric\n",
    "        \"\"\"\n",
    "        if simulated_data_mu is None or simulated_data_h is None:\n",
    "            return np.inf  # Reject if simulation failed\n",
    "            \n",
    "        # Calculate chi-squared for distance modulus\n",
    "        chi2_mu = np.sum(((observed_data_mu - simulated_data_mu) / errors_mu)**2)\n",
    "        \n",
    "        # Calculate chi-squared for Hubble parameter  \n",
    "        chi2_h = np.sum(((observed_data_h - simulated_data_h) / errors_h)**2)\n",
    "        \n",
    "        # Combined distance (could weight these differently if needed)\n",
    "        total_distance = chi2_mu + chi2_h\n",
    "        \n",
    "        return total_distance\n",
    "\n",
    "    accepted_particles = []\n",
    "    total_simulations = 0\n",
    "    distances = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Starting ABC rejection with combined distance modulus and Hubble data.\")\n",
    "        print(f\"Need to accept {n_accepted} particles.\")\n",
    "        print(f\"Tolerance: $\\\\epsilon$ = {epsilon}\")\n",
    "        print(f\"Maximum simulations: {max_simulations}\")\n",
    "        print(f\"Number of distance points: {len(zcmb)}\")\n",
    "        print(f\"Number of Hubble points: {len(z_obs)}\")\n",
    "    \n",
    "    while len(accepted_particles) < n_accepted and total_simulations < max_simulations:\n",
    "        # Sample from prior\n",
    "        w0_par = prior_w0()\n",
    "        wa_par = prior_wa()\n",
    "        \n",
    "        try:\n",
    "            # Simulate both datasets\n",
    "            simulated_mu = mu_sim(w0_par, wa_par)\n",
    "            simulated_h = Hubble_sim(w0_par, wa_par)\n",
    "            \n",
    "            # Check if simulations were successful\n",
    "            if simulated_mu is None or simulated_h is None:\n",
    "                total_simulations += 1\n",
    "                continue\n",
    "                \n",
    "            # Calculate combined distance\n",
    "            d = combined_distance(observed_data_mu, errors_mu, observed_data_h, errors_h, \n",
    "                                 simulated_mu, simulated_h)\n",
    "            distances.append(d)\n",
    "            \n",
    "            # Accept if within tolerance\n",
    "            if d <= epsilon:\n",
    "                accepted_particles.append((w0_par, wa_par, d, simulated_mu, simulated_h))\n",
    "                \n",
    "                if verbose and len(accepted_particles) % max(1, n_accepted//10) == 0:\n",
    "                    print(f\"Accepted {len(accepted_particles)}/{n_accepted} particles. \"\n",
    "                          f\"Acceptance rate: {len(accepted_particles)/total_simulations:.6f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Simulation failed for w0={w0_par:.3f}, wa={wa_par:.3f}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        total_simulations += 1\n",
    "        \n",
    "        if verbose and total_simulations % n_sims_before_update == 0:\n",
    "            current_rate = len(accepted_particles)/total_simulations if total_simulations > 0 else 0\n",
    "            print(f\"Completed {total_simulations} simulations. \"\n",
    "                  f\"Accepted: {len(accepted_particles)}. \"\n",
    "                  f\"Current acceptance rate: {current_rate:.6f}\")\n",
    "    \n",
    "    if verbose:\n",
    "        if total_simulations >= max_simulations:\n",
    "            print(f\"Stopped early! Reached maximum simulations ({max_simulations}).\")\n",
    "        final_rate = len(accepted_particles)/total_simulations if total_simulations > 0 else 0\n",
    "        print(f\"Completed! Total simulations: {total_simulations}. \"\n",
    "              f\"Final acceptance rate: {final_rate:.6f}\")\n",
    "\n",
    "    # Extract results\n",
    "    accepted_w0 = np.array([p[0] for p in accepted_particles])\n",
    "    accepted_wa = np.array([p[1] for p in accepted_particles])\n",
    "    accepted_d = np.array([p[2] for p in accepted_particles])\n",
    "    accepted_mu = np.array([p[3] for p in accepted_particles])  # All accepted distance moduli\n",
    "    accepted_h = np.array([p[4] for p in accepted_particles])   # All accepted Hubble values\n",
    "    \n",
    "    return {\n",
    "        'w0': accepted_w0,\n",
    "        'wa': accepted_wa, \n",
    "        'distances': accepted_d,\n",
    "        'mu_simulations': accepted_mu,\n",
    "        'h_simulations': accepted_h,\n",
    "        'total_simulations': total_simulations,\n",
    "        'all_distances': np.array(distances)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60312f0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simulator_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m epsilon_combined \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# May need adjustment for combined distance\u001b[39;00m\n\u001b[1;32m      3\u001b[0m n_accepted_combined \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m      6\u001b[0m accepted_w0_comb, accepted_wa_comb, accepted_d_comb, total_sim_comb \u001b[38;5;241m=\u001b[39m rejection_sim_cpl(\n\u001b[0;32m----> 7\u001b[0m    prior_w0, prior_wa, simulator_combined, combined_distance,\n\u001b[1;32m      8\u001b[0m    {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhubble\u001b[39m\u001b[38;5;124m'\u001b[39m: mock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhubble\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msn\u001b[39m\u001b[38;5;124m'\u001b[39m: mock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msn\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbao\u001b[39m\u001b[38;5;124m'\u001b[39m: mock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbao\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]},\n\u001b[1;32m      9\u001b[0m    {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhubble\u001b[39m\u001b[38;5;124m'\u001b[39m: mock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhubble\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msn\u001b[39m\u001b[38;5;124m'\u001b[39m: mock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msn\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbao\u001b[39m\u001b[38;5;124m'\u001b[39m: mock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbao\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m]},\n\u001b[1;32m     10\u001b[0m    epsilon_combined, n_accepted_combined,\n\u001b[1;32m     11\u001b[0m    weights\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhubble\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msn\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbao\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m}\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simulator_combined' is not defined"
     ]
    }
   ],
   "source": [
    " # Run ABC with combined data\n",
    "epsilon_combined = 100  # May need adjustment for combined distance\n",
    "n_accepted_combined = 200\n",
    "\n",
    "\n",
    "accepted_w0_comb, accepted_wa_comb, accepted_d_comb, total_sim_comb = (prior_w0, prior_wa, zcmb, z_obs, observed_data_mu, hub_obs, errors_mu, hub,\n",
    "                     epsilon, n_accepted, n_sims_before_update=100000, max_simulations=10**7, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
